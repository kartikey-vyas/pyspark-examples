{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fbfc6db-d6ff-4430-b745-fe7d11248251",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis\n",
    "In this notebook, we conduct some basic EDA on the 'California Housing' data set using PySpark. We are using a single machine to test out PySpark functionality for now.\n",
    "\n",
    "### Configure Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59fd7dc0-2612-4954-9a1e-db2d7fff5376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import SparkSession\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Build the SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "   .master(\"local\") \\\n",
    "   .appName(\"Linear Regression Model\") \\\n",
    "   .config(\"spark.executor.memory\", \"1gb\") \\\n",
    "   .getOrCreate()\n",
    "   \n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102ff02d-ee61-48d5-9335-d0d8c0ddc793",
   "metadata": {},
   "source": [
    "### Load and Examine Data\n",
    "> run `bash download_data.sh` in the california-housing directory to retrieve the data from the web\n",
    "\n",
    "We begin by interacting with the data as an RDD (resilient distributed dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0fd9094-4de9-4a78-8bc1-623382430afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in the data\n",
    "rdd = sc.textFile('../data/CaliforniaHousing/cal_housing.data')\n",
    "\n",
    "# Load in the header\n",
    "header = sc.textFile('../data/CaliforniaHousing/cal_housing.domain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "93546f07-4e05-4cb1-97dc-9890343052d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['longitude: continuous.',\n",
       " 'latitude: continuous.',\n",
       " 'housingMedianAge: continuous. ',\n",
       " 'totalRooms: continuous. ',\n",
       " 'totalBedrooms: continuous. ',\n",
       " 'population: continuous. ',\n",
       " 'households: continuous. ',\n",
       " 'medianIncome: continuous. ',\n",
       " 'medianHouseValue: continuous. ']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "header.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "546953d3-da3a-4b89-a11e-3031342bae92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['-122.230000,37.880000,41.000000,880.000000,129.000000,322.000000,126.000000,8.325200,452600.000000',\n",
       " '-122.220000,37.860000,21.000000,7099.000000,1106.000000,2401.000000,1138.000000,8.301400,358500.000000']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d2d4ed6-b52c-48be-bf64-b7400755e2e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['-122.230000',\n",
       "  '37.880000',\n",
       "  '41.000000',\n",
       "  '880.000000',\n",
       "  '129.000000',\n",
       "  '322.000000',\n",
       "  '126.000000',\n",
       "  '8.325200',\n",
       "  '452600.000000'],\n",
       " ['-122.220000',\n",
       "  '37.860000',\n",
       "  '21.000000',\n",
       "  '7099.000000',\n",
       "  '1106.000000',\n",
       "  '2401.000000',\n",
       "  '1138.000000',\n",
       "  '8.301400',\n",
       "  '358500.000000']]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split lines on commas\n",
    "rdd = rdd.map(lambda line: line.split(\",\"))\n",
    "\n",
    "# Inspect the first 2 lines \n",
    "rdd.take(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa02e194-1638-43f4-9977-c57ba31b0bc1",
   "metadata": {},
   "source": [
    "RDDs are fine for performing low-level transformations and actions on unstructured data. This means that we don't care about imposing a schema or accessing attributed by name or column. We should use RDDs when we want to manipulate data with functional programming constructs rather than domain specific expressions.\n",
    "\n",
    "Next, we'll convert this RDD to a DataFrame with the `toDF()` method. This is done by first applying a mapping with each of the desired column names corresponding to a different value in a row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d2c68091-56ca-4191-983f-f56b43c077ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary modules \n",
    "from pyspark.sql import Row\n",
    "\n",
    "# Map the RDD to a DF\n",
    "df = rdd.map(lambda line: Row(longitude=line[0], \n",
    "                              latitude=line[1], \n",
    "                              housingMedianAge=line[2],\n",
    "                              totalRooms=line[3],\n",
    "                              totalBedRooms=line[4],\n",
    "                              population=line[5], \n",
    "                              households=line[6],\n",
    "                              medianIncome=line[7],\n",
    "                              medianHouseValue=line[8])).toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "75425cbc-2dd2-4eb5-ba0e-e8e4c2a2d1bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+----------------+-----------+-------------+-----------+-----------+------------+----------------+\n",
      "|  longitude| latitude|housingMedianAge| totalRooms|totalBedRooms| population| households|medianIncome|medianHouseValue|\n",
      "+-----------+---------+----------------+-----------+-------------+-----------+-----------+------------+----------------+\n",
      "|-122.230000|37.880000|       41.000000| 880.000000|   129.000000| 322.000000| 126.000000|    8.325200|   452600.000000|\n",
      "|-122.220000|37.860000|       21.000000|7099.000000|  1106.000000|2401.000000|1138.000000|    8.301400|   358500.000000|\n",
      "|-122.240000|37.850000|       52.000000|1467.000000|   190.000000| 496.000000| 177.000000|    7.257400|   352100.000000|\n",
      "|-122.250000|37.850000|       52.000000|1274.000000|   235.000000| 558.000000| 219.000000|    5.643100|   341300.000000|\n",
      "|-122.250000|37.850000|       52.000000|1627.000000|   280.000000| 565.000000| 259.000000|    3.846200|   342200.000000|\n",
      "+-----------+---------+----------------+-----------+-------------+-----------+-----------+------------+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8300592c-c8b5-4ba7-a87c-5a1e466154b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
